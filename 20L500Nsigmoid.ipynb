{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4008b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import RepeatedKFold, train_test_split\n",
    "#from tensorflow_addons.activations import tanhshrink \n",
    "#from tensorflow_addons.optimizers import AdamW\n",
    "sys.path.append('../')\n",
    "from BHDVCS_tf_modi import BHDVCStf\n",
    "#import BHDVCS_tf_modified as BHDVCS  \n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "bkm10 = BHDVCStf() \n",
    " \n",
    "GPD_MODEL = 'basic'\n",
    "NUM_OF_REPLICAS = 4 \n",
    "early_stop = True\n",
    "replica = True \n",
    "cross_validation = True\n",
    "\n",
    "#datafile = r\"C:\\Users\\The god almighty\\Downloads\\pseudo_basic_BKM10_Jlab_all_t2.csv\" \n",
    "\n",
    "epochs = 8000\n",
    "\n",
    "# get (pseudo)data file\n",
    "def get_data():\n",
    "    df = pd.read_csv(r\"C:\\Users\\The god almighty\\Downloads\\pseudo_basic_BKM10_Jlab_all_t2 (1).csv\", dtype=np.float32) \n",
    "    return df\n",
    "\n",
    "# Normalize QQ, xB, t \n",
    "def normalize(QQ, xB, t):\n",
    "    QQ_norm = -1 + 2 * (QQ / 10) \n",
    "    xB_norm = -1 + 2 * (xB / 0.8)\n",
    "    t_norm = -1 + 2 * ((t + 2) / 2 )\n",
    "    return QQ_norm, xB_norm, t_norm \n",
    "\n",
    "def gen_replica(pseudo):\n",
    "    F_rep = np.random.normal(loc=pseudo['F'], scale=abs(pseudo['varF']*pseudo['F'])) # added abs for runtime error: 'ValueError: scale < 0'\n",
    "    errF_rep = pseudo['varF'] * F_rep\n",
    "    \n",
    "    replica_dict = {'set': pseudo['set'], \n",
    "                    'k': pseudo['k'], 'QQ': pseudo['QQ'], 'xB': pseudo['xB'], 't': pseudo['t'],     \n",
    "                    'phi': pseudo['phi'], 'F': F_rep,'errF': errF_rep}       \n",
    "    return replica_dict\n",
    "\n",
    "#########################################################################\n",
    "###################################################################\n",
    "################################################################## \n",
    "def build_model():  \n",
    "    model = tf.keras.Sequential() \n",
    "    model.add(tf.keras.layers.Dense(40, activation=\"sigmoid\", input_shape=(3,)))\n",
    "    for i in range(20):\n",
    "        model.add(tf.keras.layers.Dense(int(500-20*i), activation = \"sigmoid\"))\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"linear\")) \n",
    "    return model\n",
    "\n",
    "# Reduced chi2 custom Loss function (model predicted inside loss) \n",
    "def rchi2_Loss(kin, pars, F_data, F_err): #loss should be waited by the error, so that it gives mroe wheight to teh good stuff. \n",
    "    kin = tf.cast(kin, pars.dtype)\n",
    "    F_dnn = tf.reshape(bkm10.total_xs(kin, pars), [-1])\n",
    "    F_data = tf.cast(F_data, pars.dtype) \n",
    "    F_err = tf.cast(F_err, pars.dtype)\n",
    "    print(F_err)\n",
    "    loss = tf.reduce_mean(tf.square( (F_dnn - F_data) / (F_err) ) ) \n",
    "    return loss \n",
    "   \n",
    "all_ReH_map = [] #this workss\n",
    "all_ReH_1st = [] #needs more work. \n",
    "def fit_replica(i, pseudo):\n",
    "    # ----- prepare input data -----------  \n",
    "    if replica:        \n",
    "        data = gen_replica(pseudo) # generate replica \n",
    "    else:\n",
    "        data = pseudo  \n",
    " \n",
    "    kin = np.dstack((data['k'], data['QQ'] , data['xB'], data['t'], data['phi'])) \n",
    "    kin = kin.reshape(kin.shape[1:]) # loss inputs\n",
    "    QQ_norm, xB_norm, t_norm = normalize(data['QQ'] , data['xB'], data['t']) \n",
    "    kin3_norm = np.array([QQ_norm, xB_norm, t_norm]).transpose() # model inputs\n",
    "    pars_true = np.array([pseudo['ReH'], pseudo['ReE'], pseudo['ReHtilde'], pseudo['dvcs']]).transpose() # true parameters\n",
    "    # ---- split train and testing replica data samples ---- \n",
    "    if cross_validation:\n",
    "        rkf = RepeatedKFold(n_splits=10, n_repeats=10, random_state=42) \n",
    "        for train_index, test_index in rkf.split(kin):\n",
    "            kin_train, kin_test, kin3_norm_train, kin3_norm_test = kin[train_index], kin[test_index], kin3_norm[train_index], kin3_norm[test_index]\n",
    "            F_train, F_test = data['F'][train_index], data['F'][test_index]\n",
    "            Ferr_train, Ferr_test = data['errF'][train_index], data['errF'][test_index]\n",
    "    else:\n",
    "        kin_train, kin_test, kin3_norm_train, kin3_norm_test, F_train, F_test, Ferr_train, Ferr_test = train_test_split(kin, kin3_norm, data['F'], data['errF'], test_size=0.10, random_state=42)\n",
    "\n",
    "    model = build_model() \n",
    "    \n",
    "    #model.summary() \n",
    "      \n",
    "    # Instantiate an optimizer to train the model.\n",
    "    optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001, decay = .0001)\n",
    "    rmse = tf.keras.metrics.RootMeanSquaredError()\n",
    "    mape = tf.keras.metrics.MeanAbsolutePercentageError() \n",
    "\n",
    "    #model = model.compile(optimizer = optimizer, loss = rchi2_Loss) \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(loss_inputs, inputs, targets, weights):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pars = model(inputs)\n",
    "            \n",
    "            loss_value = rchi2_Loss(loss_inputs, pars, targets, weights)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        return loss_value \n",
    "        \n",
    "    @tf.function\n",
    "    def test_step(loss_inputs, inputs, targets, weights):\n",
    "        pars = model(inputs)\n",
    "        \n",
    "        val_loss_value = rchi2_Loss(loss_inputs, pars, targets, weights)\n",
    "        return val_loss_value\n",
    "    \n",
    "    # Functions to update the metrics\n",
    "    # MAPE for a given parameter: accuracy = (100 - MAPE)\n",
    "    @tf.function\n",
    "    def metricWrapper(m, kin3_norm, pars_true): \n",
    "        mape.reset_states()\n",
    "        def mapeMetric():\n",
    "            pars = model(kin3_norm)       \n",
    "            mape.update_state(pars_true[:, m], pars[:, m])\n",
    "            return tf.convert_to_tensor(mape.result(), np.float32)\n",
    "        return mapeMetric()\n",
    "    # F RMSE weighted over F_errors\n",
    "    @tf.function\n",
    "    def rmseMetric(kin, kin3_norm, pars_true, F_errors):    \n",
    "        pars = model(kin3_norm)\n",
    "        kin = tf.cast(kin, pars.dtype)        \n",
    "        pars_true = tf.cast(pars_true, pars.dtype)\n",
    "        F_dnn = tf.reshape(bkm10.total_xs(kin, pars), [-1])\n",
    "        F_true = tf.reshape(bkm10.total_xs(kin, pars_true), [-1])\n",
    "        weights = 1. / F_errors\n",
    "        rmse.update_state(F_true, F_dnn, sample_weight = weights)\n",
    "        return tf.convert_to_tensor(rmse.result(), np.float32)\n",
    " \n",
    "    # Keep results for plotting\n",
    "    train_loss_results = []\n",
    "    val_loss_results = []\n",
    "    F_rmse_results = []\n",
    "    total_mape_results = [] \n",
    "    ReH_mape_results = []\n",
    "    ReE_mape_results = []\n",
    "    ReHt_mape_results = []\n",
    "    dvcs_mape_results = []\n",
    "    predictions_results = []\n",
    "\n",
    "    patience = 100\n",
    "    wait = 0\n",
    "    best = float(\"inf\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        '''\n",
    "        model.compile(optimizer=optimizer, loss = rchi2_Loss, metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(),\n",
    "        tf.keras.metrics.FalseNegatives(),\n",
    "    ])'''\n",
    "       #train_step(loss_inputs, inputs, targets, weights)\n",
    "        \n",
    "        loss_value = train_step(kin_train, kin3_norm_train, F_train, Ferr_train)\n",
    "        val_loss_value = test_step(kin_test, kin3_norm_test, F_test, Ferr_test)\n",
    "\n",
    "        # Update metrics    \n",
    "        F_rmse = rmseMetric(kin, kin3_norm, pars_true, pseudo['errF'])\n",
    "        pars_mape = [metricWrapper(m, kin3_norm, pars_true).numpy()  for m in range(4)]\n",
    "        total_mape = np.mean(pars_mape) \n",
    "         \n",
    "        # End epoch\n",
    "        train_loss_results.append(loss_value)\n",
    "        val_loss_results.append(val_loss_value)\n",
    "        F_rmse_results.append(F_rmse)\n",
    "        total_mape_results.append(total_mape)\n",
    "        ReH_mape_results.append(pars_mape[0])\n",
    "        ReE_mape_results.append(pars_mape[1])\n",
    "        ReHt_mape_results.append(pars_mape[2])\n",
    "        dvcs_mape_results.append(pars_mape[3])\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f} val_Loss: {:.3f} F_rmse: {:.5f} ReH_mape: {:.5f} ReE_mape: {:.5f} ReHt_mape: {:.5f} dvcs_mape: {:.5f} total_mape: {:.5f}\".format(epoch, loss_value, val_loss_value, F_rmse, pars_mape[0], pars_mape[1], pars_mape[2], pars_mape[3], total_mape))\n",
    "\n",
    "        # Reset training metrics at the end of each epoch\n",
    "        rmse.reset_states() \n",
    "        mape.reset_states()\n",
    "\n",
    "        # Get prediction for one set (set 1) for visualization\n",
    "        if epoch % 10 == 0:\n",
    "            # predictions = model(kin3_norm[:1])\n",
    "            predictions = model.predict(kin3_norm[:1])\n",
    "            predictions_results.append(predictions[:1])\n",
    "\n",
    "        # Apply the early stopping strategy after 1000 epochs: stop the training if `total_mape` does not\n",
    "        # decrease over a certain number of epochs. \n",
    "        \n",
    "        '''if early_stop:\n",
    "            if epoch > 1000:\n",
    "                wait += 1\n",
    "                if total_mape < best:\n",
    "                    best = total_mape\n",
    "                    wait = 0\n",
    "                if wait >= patience:\n",
    "                    print(\"fail\")\n",
    "                    break'''  \n",
    "        if early_stop:\n",
    "            if epoch > 300:\n",
    "                wait += 1\n",
    "                if pars_mape[0] < best:\n",
    "                    best = pars_mape[0]\n",
    "                    wait = 0\n",
    "                if wait >= 50:\n",
    "                    print(\"earlyspot\")\n",
    "                    print(model.predict(kin3_norm[:1])) \n",
    "                    all_ReH_map.append(pars_mape[0])\n",
    "                    #all_ReH_1st.append(kin3_norm[:1][0])\n",
    "                    predictions_results = np.array(predictions_results); all_ReH_1st.append(predictions_results[-1,-1,0])\n",
    "                    break \n",
    "    history = {'loss': train_loss_results, 'val_loss': val_loss_results, 'ReH_mape': ReH_mape_results, 'ReE_mape': ReE_mape_results, 'ReHt_mape': ReHt_mape_results, 'dvcs_mape': dvcs_mape_results, 'total_mape': total_mape_results}\n",
    "    tf.keras.models.save_model(model, 'models/'+GPD_MODEL+'/test/fit_replica_'+str(i)+'.keras') # need \"tf.keras.models.save_model\" to save custom layer\n",
    "    np.save('models/'+GPD_MODEL+'/test/history_fit_replica_'+str(i)+'.npy',history) \n",
    "\n",
    "    predictions_results = np.array(predictions_results)\n",
    "    \n",
    "    # Draw loss metrics and predition for only the first set for visualization as a function of the number of epochs.\n",
    "    fig, axes = plt.subplots(3, sharex=True, figsize=(14, 10)) \n",
    "    fig.suptitle('Training Metrics')\n",
    "\n",
    "    # loss vs epoch\n",
    "    axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "    axes[0].plot(train_loss_results) \n",
    "    axes[0].plot(val_loss_results)\n",
    "    axes[1].set_ylabel(\"F_RMSE\", fontsize=14)\n",
    "    axes[1].plot(F_rmse_results)\n",
    "    axes[2].plot(total_mape_results)\n",
    "    axes[2].set_ylabel(\"Average Pars MAPE\", fontsize=14)\n",
    "    axes[2].set_xlabel(\"Epoch\", fontsize=14)\n",
    "\n",
    "    # Draw pars mape vs epoch\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(20, 15), sharey=False, tight_layout=True)\n",
    "    axs[0,0].plot(ReH_mape_results, label = 'mape')\n",
    "    axs[0,1].plot(ReE_mape_results, label = 'mape')\n",
    "    axs[1,0].plot(ReHt_mape_results, label = 'mape')\n",
    "    axs[1,1].plot(dvcs_mape_results, label = 'mape')\n",
    "    axs[0,0].legend(title = 'set 1')\n",
    "    axs[0,0].set_ylabel(\"$\\mathfrak{Re}\\mathcal{H}$_mape\", fontsize = 18)\n",
    "    axs[0,1].set_ylabel(\"$\\mathfrak{Re}\\mathcal{E}$_mape\", fontsize = 18)\n",
    "    axs[1,0].set_ylabel(\"$\\mathfrak{Re}\\mathcal{\\widetilde{H}}$_mape\", fontsize = 18)\n",
    "    axs[1,1].set_ylabel(\"$dvcs$_mape\", fontsize = 18) \n",
    "\n",
    "    # Draw pars pred vs epoch \n",
    "    fig2, axs2 = plt.subplots(2, 2, figsize=(20, 15), sharey=False, tight_layout=True)\n",
    "    xepoch = range(0, epoch+1, 10) \n",
    "    axs2[0,0].plot(xepoch, predictions_results[:,:,0], label = 'prediction')\n",
    "    axs2[0,0].axhline(y = pseudo['ReH'][0], color = 'r', label = 'true = '+ str('%.3g' % pseudo['ReH'][0]))\n",
    "    axs2[0,1].plot(xepoch, predictions_results[:,:,1], label = 'prediction')\n",
    "    axs2[0,1].axhline(y = pseudo['ReE'][0], color = 'r', label = 'true = '+ str('%.3g' % pseudo['ReE'][0]))\n",
    "    axs2[1,0].plot(xepoch, predictions_results[:,:,2], label = 'prediction')\n",
    "    axs2[1,0].axhline(y = pseudo['ReHtilde'][0], color = 'r', label = 'true = '+ str('%.3g' % pseudo['ReHtilde'][0])) \n",
    "    axs2[1,1].plot(xepoch, predictions_results[:,:,3], label = 'prediction')\n",
    "    axs2[1,1].axhline(y = pseudo['dvcs'][0], color = 'r', label = 'true = '+ str('%.3g' % pseudo['dvcs'][0]))\n",
    "    axs2[0,0].legend(title = 'set 1')\n",
    "    axs2[0,0].set_ylabel(\"$\\mathfrak{Re}\\mathcal{H}$\", fontsize = 18)\n",
    "    axs2[0,1].set_ylabel(\"$\\mathfrak{Re}\\mathcal{E}$\", fontsize = 18)\n",
    "    axs2[1,0].set_ylabel(\"$\\mathfrak{Re}\\mathcal{\\widetilde{H}}$\", fontsize = 18)\n",
    "    axs2[1,1].set_ylabel(\"$dvcs$\", fontsize = 18) \n",
    "    \n",
    "    plt.show() \n",
    "\n",
    "pseudo = get_data()  \n",
    "\n",
    "print(pseudo)\n",
    "\n",
    "kin = np.dstack((pseudo['k'], pseudo['QQ'] , pseudo['xB'], pseudo['t'], pseudo['phi']))\n",
    "kin = kin.reshape(kin.shape[1:]) # loss inputs\n",
    "\n",
    "print(kin)\n",
    "\n",
    "for i in range(0, NUM_OF_REPLICAS): \n",
    "    start = time.time()\n",
    "    fit_replica(i, pseudo)\n",
    "    print(\"Run Time: \", (time.time() - start)/60, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_ReH_map)\n",
    "print(all_ReH_1st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
